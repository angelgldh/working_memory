{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image processing and feature build-up\n",
    "\n",
    "This notebook loads and processes the different images used in this project. Using a Siamese network with contrastive loss, produces optimal features for downstream tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from array import array\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import transforms\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "# Custom functions and modules\n",
    "from auxFuns.process_images import *\n",
    "from auxFuns.build_features import LeNet, ContrastiveLoss, compute_pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the packages\n",
    "import auxFuns.process_images \n",
    "importlib.reload(auxFuns.process_images)\n",
    "\n",
    "import auxFuns.build_features \n",
    "importlib.reload(auxFuns.build_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.chdir('..')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the MNIST images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading of all MNIST images in training, testing and validation sets\n",
    "processed_data = os.getcwd() + '/data/MNIST/raw'\n",
    "\n",
    "# Training data\n",
    "training_images_mnist = load_mnist_images(processed_data + '/train-images-idx3-ubyte')\n",
    "training_labels_mnist = load_mnist_labels(processed_data + '/train-labels-idx1-ubyte')\n",
    "\n",
    "# Testing and validation\n",
    "all_test_images_mnist = load_mnist_images(processed_data + '/t10k-images-idx3-ubyte')\n",
    "all_test_labels_mnist = load_mnist_labels(processed_data + '/t10k-labels-idx1-ubyte')\n",
    "\n",
    "\n",
    "testing_images_mnist = all_test_images_mnist[:all_test_images_mnist.shape[0]//2 ,:,:]\n",
    "valid_images_mnist = all_test_images_mnist[all_test_images_mnist.shape[0]//2 : ,:,:]\n",
    "\n",
    "testing_labels_mnist = all_test_labels_mnist[:all_test_images_mnist.shape[0]//2]\n",
    "valid_labels_mnist = all_test_labels_mnist[all_test_images_mnist.shape[0]//2 : ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shapes of the images data : ')\n",
    "print(training_images_mnist.shape, testing_images_mnist.shape, valid_images_mnist.shape)\n",
    "\n",
    "print('\\nShapes of the labels : ')\n",
    "print((training_labels_mnist).shape, testing_labels_mnist.shape, valid_labels_mnist.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As an example, show the examples of images in the training, testing and validation sets\n",
    "index = 2 \n",
    "show_image_MNIST(training_images_mnist[index], title = 'Training image')\n",
    "show_image_MNIST(testing_images_mnist[index], title = 'Testing image')\n",
    "show_image_MNIST(valid_images_mnist[index], title = 'Validation image')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, again for visualization purposes, let us show sequence of images in training, test and validation sets\n",
    "\n",
    "sequence_length = 5\n",
    "\n",
    "#Training \n",
    "sequence_images_training = training_images_mnist[:sequence_length]\n",
    "sequence_labels_training = training_labels_mnist[:sequence_length]\n",
    "show_sequence_MNIST(sequence_images_training, sequence_labels_training)\n",
    "\n",
    "# Testing\n",
    "sequence_images_testing = testing_images_mnist[:sequence_length]\n",
    "sequence_labels_testing = testing_labels_mnist[:sequence_length]\n",
    "show_sequence_MNIST(sequence_images_testing, sequence_labels_testing)\n",
    "\n",
    "# Validation\n",
    "sequence_images_valid = valid_images_mnist[:sequence_length]\n",
    "sequence_labels_valid = valid_labels_mnist[:sequence_length]\n",
    "show_sequence_MNIST(sequence_images_valid, sequence_labels_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to preprocess the images to make them \"Pytorch-friendly\". We need all of the following steps : \n",
    "1. Normalize the Images\n",
    "\n",
    "2. Reshape for Convolutional Layer, i.e. add the channel dimension\n",
    "\n",
    "3. Create Image Pairs (label 0 for similar, 1 for dissimilar)\n",
    "\n",
    "4. Dataloader: Use a dataloader that can handle the pairs of images and labels for batching and shuffling during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the images and add the channel dimension\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "training_images_mnist = np.array([transform(image) for image in training_images_mnist])\n",
    "testing_images_mnist = np.array([transform(image) for image in testing_images_mnist])\n",
    "valid_images_mnist = np.array([transform(image) for image in valid_images_mnist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create image pairs\n",
    "training_pairs, training_labels = create_pairs_MNIST(training_images_mnist, training_labels_mnist, num_pairs=3, p=0.4)\n",
    "testing_pairs, testing_labels = create_pairs_MNIST(testing_images_mnist, testing_labels_mnist, num_pairs=3, p=0.4)\n",
    "valid_pairs, valid_labels = create_pairs_MNIST(valid_images_mnist, valid_labels_mnist, num_pairs=3, p=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the pairs of tuples into a DataLoader to feed the network\n",
    "batch_size = 64\n",
    "train_dataset, train_loader = fromtuple2loader(training_pairs, training_labels, batch_size=batch_size)\n",
    "test_dataset, test_loader = fromtuple2loader(testing_pairs, testing_labels, batch_size=batch_size)\n",
    "valid_dataset, valid_loader = fromtuple2loader(valid_pairs, valid_labels, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the Dataloader contains the correct information\n",
    "visualize_loader_pairs_MNIST(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train the Siamese network (contrastive loss)\n",
    "\n",
    "Build-up of an initial Siamese network that will bring closer similar images (similar images are defined as those whose class is the same and move away dissimilar ones). The training should follow the next steps : \n",
    "1. Forward Pass: Pass the image pairs through the network. Each leg of the Siamese network processes one image of the pair, and it should return two embeddings\n",
    "\n",
    "2. Contrastive Loss: Use the contrastive loss function to calculate the loss based on the embeddings from the Siamese network and the label indicating whether the pair is similar or dissimilar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_validation_loss(model, valid_loader, criterion):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():  # No need to track gradients for validation\n",
    "        valid_loss = 0.0\n",
    "        for data, labels in valid_loader:\n",
    "            image1, image2 = data[:,0], data[:,1]\n",
    "            labels = labels.float()\n",
    "\n",
    "            # Forward pass\n",
    "            output1 = model(image1)\n",
    "            output2 = model(image2)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = criterion.forward(output1, output2, labels)\n",
    "            valid_loss += loss.item()\n",
    "\n",
    "    return valid_loss / len(valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the net\n",
    "siamese_net = LeNet(out_dim = 4)\n",
    "\n",
    "# Key hyperparameter : the margin. It refers to the maximum allowed distance between dissimilar classes\n",
    "criterion = ContrastiveLoss(margin=2)\n",
    "\n",
    "optimizer = torch.optim.Adam(siamese_net.parameters(), lr=0.01)  \n",
    "\n",
    "num_epochs = 10 \n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "# Parameters for early stopping\n",
    "patience = 2  \n",
    "best_loss = float('inf')\n",
    "trigger_times = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (data, labels) in enumerate(train_loader):\n",
    "        image1, image2 = data[:,0], data[:,1]\n",
    "        labels = labels.float()\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        output1 = siamese_net(image1)\n",
    "        output2 = siamese_net(image2)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = criterion.forward(output1, output2, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Optimize the weights\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % 350 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{batch_idx+1}/{len(train_loader)}], Loss: {loss.item()}')\n",
    "\n",
    "\n",
    "    train_loss = compute_validation_loss(siamese_net, train_loader, criterion)\n",
    "    test_loss = compute_validation_loss(siamese_net, test_loader, criterion)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    test_losses.append(test_loss)    \n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss}')\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Test Loss: {test_loss}')\n",
    "\n",
    "    # Early stopping\n",
    "    if test_loss < best_loss:\n",
    "        best_loss = test_loss\n",
    "        trigger_times = 0\n",
    "    else:\n",
    "        trigger_times += 1\n",
    "        if trigger_times >= patience:\n",
    "            print(f\"Early stopping! Best Test Loss: {best_loss}\")\n",
    "            break\n",
    "\n",
    "torch.save(siamese_net.state_dict(), os.getcwd() + '/models/siamese_embedder.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualize the resulting features\n",
    "\n",
    "The whole goal of this notebook was to build a NNet capable of building relevant features. In this section we want to visualizae in a 3-D space that these are relevant embeddings of the images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation metrics (accuracy per class and so on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_thresholds(distances, true_labels):\n",
    "    thresholds = np.linspace(min(distances), max(distances), num=100)\n",
    "    # thresholds = np.linspace(0,1, num = 100)\n",
    "    accuracies = []\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        predictions = (distances > threshold).astype(int)\n",
    "        accuracy = accuracy_score(true_labels, predictions)\n",
    "        accuracies.append(accuracy)\n",
    "    \n",
    "    return thresholds, accuracies\n",
    "\n",
    "distances, true_labels = compute_pairwise_distances(siamese_net, valid_loader)\n",
    "thresholds, accuracies = evaluate_thresholds(distances, true_labels)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(thresholds, accuracies, label='Accuracy')\n",
    "plt.xlabel('Threshold / allowed distances to cluster')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy vs. Pairwise distance for Siamese Network')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(thresholds, accuracies, label='Accuracy')\n",
    "plt.xlabel('Threshold / allowed distances to cluster')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy vs. Pairwise distance for Siamese Network')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization in the 2D space\n",
    "\n",
    "\n",
    "THIS PART NEEDS TO BE REPEATED AGAIN AS THE RESULTS ARE MISLEADING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataset, valid_loader = fromtuple2loader(valid_pairs, valid_labels, batch_size=5000)\n",
    "\n",
    "def get_embeddings_every_3(model, data_loader):\n",
    "    model.eval()\n",
    "    embeddings = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (images, _) in enumerate(data_loader):\n",
    "            if i % 3 == 0:  # Process only every third image\n",
    "                image1 = images[:,0]  # Assuming you're interested in embeddings of image1\n",
    "                emb = model(image1).numpy()  # Get embeddings\n",
    "                embeddings.append(emb)\n",
    "    \n",
    "    embeddings = np.concatenate(embeddings, axis=0)\n",
    "    return embeddings\n",
    "embeddings_valid = get_embeddings_every_3(siamese_net, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_valid.shape, valid_labels_mnist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Assuming `embeddings` is your [5000, 3] array and `labels` is your (5000,) array\n",
    "def plot_embeddings_3D_and_2D(embeddings, labels):\n",
    "    fig = plt.figure(figsize=(20, 5))\n",
    "    \n",
    "    # 3D plot\n",
    "    ax = fig.add_subplot(141, projection='3d')\n",
    "    scatter = ax.scatter(embeddings[:, 0], embeddings[:, 1], embeddings[:, 2], c=labels, cmap='tab10', s=2)\n",
    "    ax.set_title('3D Embeddings')\n",
    "    legend1 = ax.legend(*scatter.legend_elements(), title=\"Classes\")\n",
    "    ax.add_artist(legend1)\n",
    "\n",
    "    # XY projection\n",
    "    ax2 = fig.add_subplot(142)\n",
    "    scatter = ax2.scatter(embeddings[:, 0], embeddings[:, 1], c=labels, cmap='tab10', s=2)\n",
    "    ax2.set_title('XY plane')\n",
    "    legend2 = ax2.legend(*scatter.legend_elements(), title=\"Classes\")\n",
    "    ax2.add_artist(legend2)\n",
    "\n",
    "    # XZ projection\n",
    "    ax3 = fig.add_subplot(143)\n",
    "    scatter = ax3.scatter(embeddings[:, 0], embeddings[:, 2], c=labels, cmap='tab10', s=2)\n",
    "    ax3.set_title('XZ plane')\n",
    "    legend3 = ax3.legend(*scatter.legend_elements(), title=\"Classes\")\n",
    "    ax3.add_artist(legend3)\n",
    "\n",
    "    # YZ projection\n",
    "    ax4 = fig.add_subplot(144)\n",
    "    scatter = ax4.scatter(embeddings[:, 1], embeddings[:, 2], c=labels, cmap='tab10', s=2)\n",
    "    ax4.set_title('YZ plane')\n",
    "    legend4 = ax4.legend(*scatter.legend_elements(), title=\"Classes\")\n",
    "    ax4.add_artist(legend4)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_embeddings_3D_and_2D(embeddings_valid[:5000], valid_labels_mnist)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
