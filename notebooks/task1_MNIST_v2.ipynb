{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1. Default Delay-Match-To-Sample (DMTS):\n",
    "\n",
    "[This notebook implements task 1 as well, also using MNIST images. However this time the\n",
    "\n",
    "A) Encoding of tasks\n",
    "\n",
    "b) Model architecure\n",
    "\n",
    "are different]\n",
    "\n",
    "A sample image is presented and then, after a time delay of arbitrary duration, a test image is presented. The\n",
    "goal is to evaluate the model's ability to retain the sample image in working memory during the delay period\n",
    "and compare it to the test image. To titrate difficulty, the similarity between sample and test images can be\n",
    "varied, and the model's invariance to image transformations and zero-shot generalization ability will also be\n",
    "evaluated.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is structured as follows : \n",
    "1. Load task 1 and visualize it\n",
    "2. Train (and evaluate/validate) a new architecture\n",
    "\n",
    "\n",
    "[The two key differences with previous approaches are : \n",
    "\n",
    "a. Every time step (every image) has an associated label\n",
    "\n",
    "b. The model produces one output per time step (per image)\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from array import array\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import transforms\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Custom functions and modules\n",
    "from auxFuns.data.task_loader import *\n",
    "from auxFuns.data.task_visualizer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the packages\n",
    "import auxFuns.data.task_loader\n",
    "importlib.reload(auxFuns.data.task_loader)\n",
    "\n",
    "import auxFuns.data.task_visualizer\n",
    "importlib.reload(auxFuns.data.task_visualizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.chdir('..')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load (and visualize) task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train the newly created architecture (ConvNet embedder > Working Memory model > Linear classifier per time step)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
